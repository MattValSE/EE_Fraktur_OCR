{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../../datasets/gold/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a8bdc",
   "metadata": {},
   "source": [
    "### With coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json  \n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path  \n",
    "\n",
    "def load_parquet_ocr_with_coords(parquet_path):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            image_path = Path(\"scanned\") / row[\"Newspaper\"] / \"image\" / f\"{row['Newspaper']}.jpg\"\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Image error: {e} for {image_path}\")\n",
    "            continue\n",
    "\n",
    "      \n",
    "        try:\n",
    "            Train_Input = row[\"Train_Input\"]\n",
    "            if isinstance(Train_Input, str):\n",
    "                Train_Input = json.loads(Train_Input)  # Use JSON for valid input\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse OCR lines for {row.get('file_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ocr_prompt_lines = []\n",
    "        for i, line in enumerate(Train_Input.get(\"lines\", [])):\n",
    "            if \"text\" in line:\n",
    "                coords = line.get(\"coords\", \"?\")\n",
    "                ocr_prompt_lines.append(f\"{i+1}. ({coords}): {line['text']}\")\n",
    "\n",
    "        ocr_prompt = \"OCR lines with coordinates:\\n\" + \"\\n\".join(ocr_prompt_lines)\n",
    "\n",
    "        sample = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": (\n",
    "                        \"Below is the image of one page of a document, as well as some raw textual content that was \"\n",
    "                        \"previously extracted for it. Just return the plain text representation of this document as if \"\n",
    "                        \"you were reading it naturally. Do not hallucinate.\"\n",
    "                    )}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": ocr_prompt},\n",
    "                        {\"type\": \"image\", \"image\": image}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": row[\"Train_Output\"]}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        samples.append(sample)\n",
    "\n",
    "    return Dataset.from_list(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58510f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_parquet_ocr_with_coords(\"olmocr_train.parquet\")\n",
    "dataset.save_to_disk(\"processed_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8162e0",
   "metadata": {},
   "source": [
    "### Without coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json  # ‚Üê use this instead of ast\n",
    "from datasets import Dataset, DatasetDict\n",
    "from PIL import Image\n",
    "from pathlib import Path  \n",
    "\n",
    "def load_parquet_ocr(parquet_path):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            image_path = Path(\"scanned\") / row[\"Newspaper\"] / \"image\" / f\"{row['Newspaper']}.jpg\"\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Image error: {e} for {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Parse OCR lines using JSON, not ast\n",
    "        try:\n",
    "            Train_Input = row[\"Train_Input\"]\n",
    "            if isinstance(Train_Input, str):\n",
    "                Train_Input = json.loads(Train_Input)  # Use JSON for valid input\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse OCR lines for {row.get('file_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ocr_prompt_lines = []\n",
    "        for i, line in enumerate(Train_Input.get(\"lines\", [])):\n",
    "            if \"text\" in line:\n",
    "                ocr_prompt_lines.append(f\"{i+1}. {line['text']}\")\n",
    "\n",
    "        ocr_prompt = \"\\n\".join(ocr_prompt_lines)\n",
    "\n",
    "        sample = {\n",
    "            \"messages\": [\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": (\n",
    "                \"Below is the image of one page of a document, as well as some raw textual content that was \"\n",
    "                \"previously extracted for it. Just return the plain text representation of this document as if \"\n",
    "                \"you were reading it naturally. Do not hallucinate.\"\n",
    "            )}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"{ocr_prompt}\\n\"  #\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image  \n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": row[\"Train_Output\"]}]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "        samples.append(sample)\n",
    "\n",
    "    full_dataset = Dataset.from_list(samples)\n",
    "    split_dataset = full_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "    return split_dataset  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_parquet_ocr(\"olmocr_train.parquet\")\n",
    "dataset.save_to_disk(\"processed_dataset_nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def extract_image(example):\n",
    "    \"\"\"Extract image from example, return None if no image found\"\"\"\n",
    "    try:\n",
    "        for message in example[\"messages\"]:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                for item in message[\"content\"]:\n",
    "                    if item[\"type\"] == \"image\":\n",
    "                        img_data = item[\"image\"]\n",
    "                        if isinstance(img_data, dict) and \"bytes\" in img_data:\n",
    "                            img = Image.open(io.BytesIO(img_data[\"bytes\"])).convert(\"RGB\")\n",
    "                            print(f\"  Extracted image size: {img.size}\")\n",
    "                            return img\n",
    "                        elif isinstance(img_data, Image.Image):\n",
    "                            print(f\"  Found PIL Image, size: {img_data.size}\")\n",
    "                            return img_data\n",
    "                        else:\n",
    "                            print(f\"Warning: Unsupported image format: {type(img_data)}\")\n",
    "                            return None\n",
    "        return None  # No image found\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting image: {e}\")\n",
    "        return None\n",
    "\n",
    "def has_image(example):\n",
    "    \"\"\"Check if example has an image\"\"\"\n",
    "    return extract_image(example) is not None\n",
    "\n",
    "def debug_text_content(example):\n",
    "    \"\"\"Debug the text content to check for image references\"\"\"\n",
    "    for message in example[\"messages\"]:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            for item in message[\"content\"]:\n",
    "                if item[\"type\"] == \"text\":\n",
    "                    text = item.get(\"text\", \"\")\n",
    "                    # Count potential image tokens/references\n",
    "                    image_refs = text.count(\"<image>\") + text.count(\"[IMAGE]\") + text.count(\"<img>\")\n",
    "                    if image_refs > 0:\n",
    "                        print(f\"  Text contains {image_refs} image references\")\n",
    "                    print(f\"  Text preview: {text[:200]}...\")\n",
    "\n",
    "def debug_dataset_detailed(dataset, num_examples=5):\n",
    "    \"\"\"Enhanced debug function to check dataset structure\"\"\"\n",
    "    print(f\"Debugging first {num_examples} examples in detail:\")\n",
    "    \n",
    "    for i in range(min(num_examples, len(dataset['train']))):\n",
    "        print(f\"\\n=== Example {i} ===\")\n",
    "        example = dataset['train'][i]\n",
    "        \n",
    "        # Check if example has image\n",
    "        has_img = has_image(example)\n",
    "        print(f\"Has image: {has_img}\")\n",
    "        \n",
    "        # Debug message structure\n",
    "        for j, message in enumerate(example[\"messages\"]):\n",
    "            print(f\"Message {j} - Role: {message['role']}\")\n",
    "            content = message.get(\"content\", [])\n",
    "            print(f\"  Content items: {len(content)}\")\n",
    "            \n",
    "            for k, item in enumerate(content):\n",
    "                item_type = item.get(\"type\", \"unknown\")\n",
    "                print(f\"    Item {k}: type={item_type}\")\n",
    "                \n",
    "                if item_type == \"image\":\n",
    "                    img_data = item.get(\"image\")\n",
    "                    if isinstance(img_data, dict) and \"bytes\" in img_data:\n",
    "                        print(f\"      Image data: dict with bytes ({len(img_data['bytes'])} bytes)\")\n",
    "                    else:\n",
    "                        print(f\"      Image data type: {type(img_data)}\")\n",
    "                \n",
    "                elif item_type == \"text\":\n",
    "                    text = item.get(\"text\", \"\")\n",
    "                    # Check for image references in text\n",
    "                    image_tokens = text.count(\"<image>\")\n",
    "                    print(f\"      Text length: {len(text)}, <image> tokens: {image_tokens}\")\n",
    "                    if image_tokens > 1:\n",
    "                        print(f\"      WARNING: Multiple <image> tokens found!\")\n",
    "\n",
    "\n",
    "# Run the detailed debugging\n",
    "debug_dataset_detailed(dataset)\n",
    "\n",
    "# Test with your original examples\n",
    "examples = [dataset['train'][0], dataset['train'][1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae16122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Value, Image as HfImage\n",
    "\n",
    "def load_parquet_ocr(parquet_path):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            image_path = Path(\"scanned\") / row[\"Newspaper\"] / \"image\" / f\"{row['Newspaper']}.jpg\"\n",
    "            if not image_path.exists():\n",
    "                print(f\"Missing image: {image_path}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Image error: {e} for {image_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            Train_Input = json.loads(row[\"Train_Input\"]) if isinstance(row[\"Train_Input\"], str) else row[\"Train_Input\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse OCR lines for {row.get('file_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ocr_prompt_lines = [f\"{i+1}. {line['text']}\" for i, line in enumerate(Train_Input.get(\"lines\", [])) if \"text\" in line]\n",
    "        ocr_prompt = \"\\n\".join(ocr_prompt_lines)\n",
    "\n",
    "        sample = {\n",
    "            \"image\": str(image_path),  # Store path instead of PIL.Image\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": (\n",
    "                        \"Below is the image of one page of a document, as well as some raw textual content that was \"\n",
    "                        \"previously extracted for it. Just return the plain text representation of this document as if \"\n",
    "                        \"you were reading it naturally. Do not hallucinate.\"\n",
    "                    )}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": ocr_prompt},\n",
    "                        {\"type\": \"image\", \"image\": str(image_path)}  # Optional, see note below\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": row[\"Train_Output\"]}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        samples.append(sample)\n",
    "\n",
    "    # Define custom features so images are properly loaded by HF datasets\n",
    "    features = Features({\n",
    "        \"image\": HfImage(),  # This tells HF to load images from file paths\n",
    "        \"messages\": Value(\"string\"),  # Store messages as serialized JSON string\n",
    "    })\n",
    "\n",
    "    # Serialize messages for HF Dataset\n",
    "    for s in samples:\n",
    "        s[\"messages\"] = json.dumps(s[\"messages\"])\n",
    "\n",
    "    dataset = Dataset.from_list(samples, features=features)\n",
    "    split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "    return split_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f1aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_parquet_ocr(\"olmocr_train.parquet\")\n",
    "dataset.save_to_disk(\"processed_dataset_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_image(example):\n",
    "    \"\"\"Extract image from example, return None if no image found\"\"\"\n",
    "    try:\n",
    "        for message in example[\"messages\"]:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                for item in message[\"content\"]:\n",
    "                    if item[\"type\"] == \"image\":\n",
    "                        img_data = item[\"image\"]\n",
    "                        if isinstance(img_data, str):  # Path to image\n",
    "                            img_path = Path(img_data)\n",
    "                            if img_path.exists():\n",
    "                                img = Image.open(img_path).convert(\"RGB\")\n",
    "                                print(f\"  Loaded image from path: {img_path}, size: {img.size}\")\n",
    "                                return img\n",
    "                            else:\n",
    "                                print(f\"  Image path does not exist: {img_path}\")\n",
    "                                return None\n",
    "                        elif isinstance(img_data, dict) and \"bytes\" in img_data:\n",
    "                            img = Image.open(io.BytesIO(img_data[\"bytes\"])).convert(\"RGB\")\n",
    "                            print(f\"  Extracted image from bytes, size: {img.size}\")\n",
    "                            return img\n",
    "                        elif isinstance(img_data, Image.Image):\n",
    "                            print(f\"  Found PIL Image, size: {img_data.size}\")\n",
    "                            return img_data\n",
    "                        else:\n",
    "                            print(f\"Warning: Unsupported image format: {type(img_data)}\")\n",
    "                            return None\n",
    "        return None  # No image found\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting image: {e}\")\n",
    "        return None\n",
    "\n",
    "def has_image(example):\n",
    "    \"\"\"Check if example has an image\"\"\"\n",
    "    return extract_image(example) is not None\n",
    "\n",
    "def debug_text_content(example):\n",
    "    \"\"\"Debug the text content to check for image references\"\"\"\n",
    "    for message in example[\"messages\"]:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            for item in message[\"content\"]:\n",
    "                if item[\"type\"] == \"text\":\n",
    "                    text = item.get(\"text\", \"\")\n",
    "                    image_refs = text.count(\"<image>\") + text.count(\"[IMAGE]\") + text.count(\"<img>\")\n",
    "                    if image_refs > 0:\n",
    "                        print(f\"  Text contains {image_refs} image references\")\n",
    "                    print(f\"  Text preview: {text[:200]}...\")\n",
    "\n",
    "def debug_dataset_detailed(dataset, num_examples=5):\n",
    "    \"\"\"Enhanced debug function to check dataset structure\"\"\"\n",
    "    print(f\"Debugging first {num_examples} examples in detail:\")\n",
    "    \n",
    "    for i in range(min(num_examples, len(dataset['train']))):\n",
    "        print(f\"\\n=== Example {i} ===\")\n",
    "        example = dataset['train'][i]\n",
    "\n",
    "        # üí° Fix: Parse messages from JSON string\n",
    "        try:\n",
    "            messages = json.loads(example[\"messages\"])\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR parsing messages: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Check if example has image\n",
    "        example[\"messages\"] = messages  # temporarily inject parsed messages\n",
    "        has_img = has_image(example)\n",
    "        print(f\"Has image: {has_img}\")\n",
    "        \n",
    "        # Debug message structure\n",
    "        for j, message in enumerate(messages):\n",
    "            print(f\"Message {j} - Role: {message['role']}\")\n",
    "            content = message.get(\"content\", [])\n",
    "            print(f\"  Content items: {len(content)}\")\n",
    "            \n",
    "            for k, item in enumerate(content):\n",
    "                item_type = item.get(\"type\", \"unknown\")\n",
    "                print(f\"    Item {k}: type={item_type}\")\n",
    "                \n",
    "                if item_type == \"image\":\n",
    "                    img_data = item.get(\"image\")\n",
    "                    print(f\"      Image data: {img_data}\")  # Should be path\n",
    "                elif item_type == \"text\":\n",
    "                    text = item.get(\"text\", \"\")\n",
    "                    image_tokens = text.count(\"<image>\")\n",
    "                    print(f\"      Text length: {len(text)}, <image> tokens: {image_tokens}\")\n",
    "                    if image_tokens > 1:\n",
    "                        print(f\"      WARNING: Multiple <image> tokens found!\")\n",
    "\n",
    "# Example usage:\n",
    "debug_dataset_detailed(dataset)\n",
    "\n",
    "# If needed: test specific samples\n",
    "# examples = [dataset['train'][0], dataset['train'][1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2e8b5",
   "metadata": {},
   "source": [
    "## Block dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Value, Image as HfImage\n",
    "import pandas as pd\n",
    "import json  \n",
    "from PIL import Image\n",
    "from pathlib import Path \n",
    "\n",
    "MAX_CHARS = 6000\n",
    "\n",
    "def load_block_parquet_ocr(parquet_path):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    df = df[df[\"Block\"].notna() & (df[\"Block\"].str.strip() != \"\")]\n",
    "    #print(df)\n",
    "    \n",
    "    samples = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        Train_Input = None\n",
    "        Train_Output = None\n",
    "        ocr_prompt = \"\"\n",
    "        ocr_prompt_assist = \"\"\n",
    "    \n",
    "        try:\n",
    "            image_path = Path(\"scanned\") / row[\"Newspaper\"] / \"image\" / f\"{row['Block']}.jpg\"\n",
    "            if not image_path.exists():\n",
    "                print(f\"Missing image: {image_path}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Image error: {e} for {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parse Train_Input\n",
    "            if isinstance(row[\"Train_Input\"], dict):\n",
    "                Train_Input = row[\"Train_Input\"]\n",
    "            elif isinstance(row[\"Train_Input\"], str) and row[\"Train_Input\"].strip().startswith(\"{\"):\n",
    "                Train_Input = json.loads(row[\"Train_Input\"])\n",
    "            else:\n",
    "                Train_Input = {\"lines\": [{\"text\": line.strip()} for line in row[\"Train_Input\"].split(\"\\n\") if line.strip()]}\n",
    "    \n",
    "            # Parse Train_Output\n",
    "            if isinstance(row[\"Train_Output\"], dict):\n",
    "                Train_Output = row[\"Train_Output\"]\n",
    "            elif isinstance(row[\"Train_Output\"], str) and row[\"Train_Output\"].strip().startswith(\"{\"):\n",
    "                Train_Output = json.loads(row[\"Train_Output\"])\n",
    "            else:\n",
    "                Train_Output = {\"lines\": [{\"text\": line.strip()} for line in row[\"Train_Output\"].split(\"\\n\") if line.strip()]}\n",
    "    \n",
    "            # Build prompt text from parsed structures\n",
    "            ocr_prompt = \"\\n\".join(line[\"text\"] for line in Train_Input.get(\"lines\", []))\n",
    "            ocr_prompt_assist = \"\\n\".join(line[\"text\"] for line in Train_Output.get(\"lines\", []))\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse OCR lines for {row.get('Block', 'unknown')}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        sample = {\n",
    "            \"image\": str(image_path),\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": (\n",
    "                        \"Below is the image of one page of a document, as well as some raw textual content that was \"\n",
    "                        \"previously extracted for it. Just return the plain text representation of this document as if \"\n",
    "                        \"you were reading it naturally. Do not hallucinate.\"\n",
    "                    )}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": ocr_prompt},\n",
    "                        {\"type\": \"image\", \"image\": str(image_path)}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": ocr_prompt_assist}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        samples.append(sample)\n",
    "\n",
    "\n",
    "    # Define custom features so images are properly loaded by HF datasets\n",
    "    features = Features({\n",
    "        \"image\": HfImage(),  # This tells HF to load images from file paths\n",
    "        \"messages\": Value(\"string\"),  # Store messages as serialized JSON string\n",
    "    })\n",
    "\n",
    "    # Serialize messages for HF Dataset\n",
    "    for s in samples:\n",
    "        s[\"messages\"] = json.dumps(s[\"messages\"])\n",
    "\n",
    "    dataset = Dataset.from_list(samples, features=features)\n",
    "    split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Secondary split: 10% of the training set ‚Üí validation\n",
    "    split_dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)[\"train\"],\n",
    "    \"validation\": split_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)[\"test\"],\n",
    "    \"test\": split_dataset[\"test\"]\n",
    "    })\n",
    "    return split_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79310295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_block_parquet_ocr(\"olmocr_train.parquet\")\n",
    "dataset.save_to_disk(\"block_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697aab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for example in dataset[\"validation\"]:\n",
    "    messages = json.loads(example[\"messages\"])  # stored as a serialized string\n",
    "    assistant_msg = next((m for m in messages if m[\"role\"] == \"assistant\"), None)\n",
    "    print(\"---\")\n",
    "    assistant_text = assistant_msg['content'][0]['text']\n",
    "    #if assistant_text is None:\n",
    "    #    print(1)\n",
    "    pprint(assistant_msg['content'][0]['text'])\n",
    "#print(assistant_msg['content'][1][\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6af70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "example = dataset[\"validation\"][0]\n",
    "trg = example['image'].filename\n",
    "\n",
    "pprint(type(trg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
